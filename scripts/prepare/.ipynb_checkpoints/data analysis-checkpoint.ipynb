{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import pandas as pd\n",
    "sns.set()\n",
    "\n",
    "with open(\"../../hyperparams.yml\", 'r') as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "    \n",
    "data_dir=configs['data_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>seqs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4Y28</td>\n",
       "      <td>MATVTTQASAAIFGPCGLKSRFLGGSSGKLNRGVAFRPVGCSPSAS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2JXZ</td>\n",
       "      <td>CGNLSTCMLGTLTQDFHKFHTFPQTNTGVGTPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4P15</td>\n",
       "      <td>GRFSERAQKVLALSQEEAIRLSHHNIGTEHILLGLIREGEGIAAKA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4CYJ</td>\n",
       "      <td>GSMPLSSIGLPYYREPLFSAWPADIISDVGAPPLQLEPSFVATLKQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2Z51</td>\n",
       "      <td>MVPLTEENVESVLDEIRPYLMSDGGNVALHEIDGNVVRVKLQGACG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdb_id                                               seqs\n",
       "0   4Y28  MATVTTQASAAIFGPCGLKSRFLGGSSGKLNRGVAFRPVGCSPSAS...\n",
       "1   2JXZ                  CGNLSTCMLGTLTQDFHKFHTFPQTNTGVGTPA\n",
       "2   4P15  GRFSERAQKVLALSQEEAIRLSHHNIGTEHILLGLIREGEGIAAKA...\n",
       "3   4CYJ  GSMPLSSIGLPYYREPLFSAWPADIISDVGAPPLQLEPSFVATLKQ...\n",
       "4   2Z51  MVPLTEENVESVLDEIRPYLMSDGGNVALHEIDGNVVRVKLQGACG..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv(data_dir+'raw/csv/training_90.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49600\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequences Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyse length distribution\n",
    "dataset['len']=dataset['seqs'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    49600.000000\n",
       "mean       230.238770\n",
       "std        178.504938\n",
       "min         20.000000\n",
       "25%        112.000000\n",
       "50%        187.000000\n",
       "75%        304.000000\n",
       "max       4914.000000\n",
       "Name: len, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=512\n",
    "dataset=dataset[dataset['len']<=(max_length-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46698\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amino acids analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, 'M': 1, 'A': 2, 'T': 3, 'V': 4, 'Q': 5, 'S': 6, 'I': 7, 'F': 8, 'G': 9, 'P': 10, 'C': 11, 'L': 12, 'K': 13, 'R': 14, 'N': 15, 'E': 16, 'W': 17, 'Y': 18, 'D': 19, 'H': 20, '<BOS>': 21, '<EOS>': 22}\n"
     ]
    }
   ],
   "source": [
    "aminos_vocabulary={'<PAD>':0}\n",
    "for seq in dataset['seqs']:\n",
    "    for aa in seq:\n",
    "        if aa not in aminos_vocabulary:\n",
    "            aminos_vocabulary[aa]=len(aminos_vocabulary)\n",
    "\n",
    "aminos_vocabulary['<BOS>']=len(aminos_vocabulary)\n",
    "aminos_vocabulary['<EOS>']=len(aminos_vocabulary)\n",
    "print(aminos_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_encoded=[]\n",
    "for seq in dataset['seqs']:\n",
    "    encoded_seq=[aminos_vocabulary['<BOS>']]\n",
    "    for aa in seq:\n",
    "        encoded_seq.append(aminos_vocabulary[aa])\n",
    "    encoded_seq.append(aminos_vocabulary['<EOS>'])\n",
    "    \n",
    "    if len(encoded_seq)<max_length:\n",
    "        padding_size=max_length-len(encoded_seq)\n",
    "        for i in range(padding_size):\n",
    "            encoded_seq.append(aminos_vocabulary['<PAD>'])\n",
    "    dataset_encoded.append(encoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46698, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_encoded=np.stack(dataset_encoded)\n",
    "dataset_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\n",
    "    'sequence_length':max_length,\n",
    "    'aa_vocabulary': aminos_vocabulary\n",
    "}\n",
    "\n",
    "with open(data_dir+'dataset_config.yaml', 'w') as outfile:\n",
    "    yaml.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(data_dir+'dataset/training_90.npy', dataset_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Test and Validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 512)\n"
     ]
    }
   ],
   "source": [
    "dataset_encoded=[]\n",
    "for dataset_name in ['testing', 'validation']:\n",
    "    dataset=pd.read_csv(data_dir+'raw/csv/'+dataset_name+'.csv')\n",
    "    dataset['len']=dataset['seqs'].str.len()\n",
    "    dataset=dataset[dataset['len']<=(max_length-2)]\n",
    "    \n",
    "    for seq in dataset['seqs']:\n",
    "        encoded_seq=[aminos_vocabulary['<BOS>']]\n",
    "        for aa in seq:\n",
    "            encoded_seq.append(aminos_vocabulary[aa])\n",
    "        encoded_seq.append(aminos_vocabulary['<EOS>'])\n",
    "\n",
    "        if len(encoded_seq)<max_length:\n",
    "            padding_size=max_length-len(encoded_seq)\n",
    "            for i in range(padding_size):\n",
    "                encoded_seq.append(aminos_vocabulary['<PAD>'])\n",
    "        dataset_encoded.append(encoded_seq)\n",
    "        \n",
    "dataset_encoded=np.stack(dataset_encoded)\n",
    "print(dataset_encoded.shape)\n",
    "np.save(data_dir+'dataset/evaluation.npy', dataset_encoded)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
